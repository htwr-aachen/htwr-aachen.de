---
title: Inferenzstatistik
description: KP
author: Jonas Schneider
date: 26/07/2023
order: 7
tags: [Inferenzstatistik, Statistik, Likelihood]
---

## Wasdas

Nehme an wir hätten eine Umfrage gemacht: 50 Leute wurden gefragt, ob sie _AFI_ mögen. 45 davon sagen ja sehr. 5 sagen nein.
Jetzt müssen wir diese Umfrage bewerten. Wie gut ist die Stichprobe, wie kann ich nachweisen, dass der Anteil der Leute, die _AFI_ mögen, wirklich so hoch ist?

<Spoiler>kannst du nicht.</Spoiler>

Die Vorlesung gibt 3 gute Schritte:

1. Finde ein geeignetes Verteilungsmodell: $Bin(n,p), n = 50$
2. Finde die optimalen Parameter: $p$.
3. Wie kann ich die Hypothese testen, und ist $p > 0.5$ nachweisbar?

### Grundbegriffe

$X = \{X(w) | w \in \Omega\} \subset \mathbb{R}^n$ ist der **Stichprobenraum**
$x = (x_1, ..., x_n) \in X$ ist eine **Stichprobe**

$X$ ist eine Zufallsvariable, $x$ ist eine Realisierung der Zufallsvariable $X$.
$\mathcal{P}$ heißt Verteilungsmodell auf $\mathbb{R}^n$, genauer heißt es **parametrisches Verteilungsmodell**, falls $\mathcal{P} = \{ \mathcal{P}_\vartheta | \vartheta \in \Theta\}$ wobei $\Theta$ eine Menge von Parametervektoren für die Verteilungen sind.

Falls es nicht endlichdimensional parametrisiert werden kann, heißt es **nichtparametrisches Verteilungsmodell**.

### Statistik

Dummer Name

Eine **Statistik** ist eine messbare Abbildung $T: \mathbb{R}^n \rightarrow \mathbb{R}^d$, wobei oft $d = 1$

Wenn $T$ in den Parameterraum $\Theta$ abbildet, heißt sie **Schätzer**.

Die **empirische Verteilungsfunktion** ist wie bereits gesagt: $\~{F}_n(x) = \frac{1}{n} \sum_{i=1}^n \mathbb{1}_{(-\infty, x]}(X_i)$. Das ist einfach eine tolle Schreibweise um zu sagen:
Gegeben ein Wert $x$, wie viele Datewerte sind kleiner oder gleich $x$. Es ist einfach zählen, die Anzahl dann noch relativ zu Gesamtdatenmenge und fertig.

Es gilt: $E(\~{F}_n(x)) = P(X_i \le x) = F(x), Var(\~{F}_n(x)) = \frac{F(x)(1-F(x))}{n}$. Zudem konvergiert $\~{F}_n(x)$ immer gegen $F(x)$.

### Likelihood-Prinzip und Funktionen

Ist ein Schätzprinzip und sagt, dass die beste Schätzung diejenige ist, die die beobachteten Daten am wahrscheinlichsten macht.
Hierfür gibt es mehrere Funktionen und vorallem **ein Schema**:

**Likelihood-Fkt**: $L(\vartheta \mid x) = p_\vartheta (x)$
**Log-Likelihood-Fkt**: $l(\vartheta \mid x) = \log(L(\vartheta \mid x))$
**Max-Likelihood-Fkt**: $p_{\hat{\vartheta}}(x) \ge p_\vartheta(x) \forall \vartheta \in \Theta$

Bei Stichproben gilt: $L(\vartheta \mid x_1, ..., x_n) = \prod_{i=1}^n L(\vartheta \mid x_i)$

## Maximum Likelihood Schätzer Schema

1. Likelihood-Funktion aufstellen $L(\vartheta \mid X_1, ..., X_n)$ bei gegebenen Daten (genannt Realisationen) $x_1, ..., x_n$
2. Log-Likelihood-Fkt aufstellen $l(\vartheta) = \log(L(\vartheta \mid x_1, ..., x_n))$
3. Kritische Punkte berechnen: $l'(\vartheta) = 0$, also Kandidaten für Extrema
4. Zeigen, dass eins lokales Maximum ist, also $l''(\vartheta) < 0$.
5. Zeigen das es ein globales Maximum ist. 